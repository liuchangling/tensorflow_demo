{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取数据文件\n",
    "df = pd.read_csv('./boston.csv', header=0)\n",
    "#print(df.describe())\n",
    "\n",
    "# 获取df值\n",
    "df = df.values\n",
    "# 转成numpy处理\n",
    "df = np.array(df) \n",
    "\n",
    "# version 2 增加这两行，归一化处理 即数据预处理\n",
    "# 对0-11列即x向量进行归一化操作，不改变Y向量。\n",
    "for i in range(12):\n",
    "    df[:,i] = (df[:,i] - df[:].min())/(df[:].max() - df[:].min())\n",
    "\n",
    "\n",
    "# x_data 为所有行，前12列的特征数据\n",
    "x_data = df[:,:12]\n",
    "# y_data 为所有行第13列的特征数据\n",
    "y_data = df[:,12]\n",
    "\n",
    "#定义特征数据和标签数据的站位符.因为不知道多少行所以第一项填None\n",
    "# shape中None表示行的数量未知，在实际训练时，决定一次代入多少行样本，\n",
    "# 从一个样本的随机SDG到批量SDG都可以\n",
    "x = tf.placeholder(tf.float32, [None, 12], name = 'X')\n",
    "y = tf.placeholder(tf.float32, [None, 1], name = \"Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义命名空间，使得计算图更可读\n",
    "with tf.name_scope(\"model\"):\n",
    "    w = tf.Variable(tf.random_normal([12, 1], stddev=0.01), name='W')\n",
    "    b = tf.Variable(1.0, name='b')\n",
    "    \n",
    "    #叉乘用 tf.matmul。 这里会将3个列向量（xwb）中第一个x转置为行向量进行叉乘\n",
    "    def model(x,w,b):\n",
    "        return tf.matmul(x,w)+b\n",
    "    \n",
    "    # 这一段和一元回归基本一样\n",
    "    pred = model(x,w,b)\n",
    "    train_epochs = 50\n",
    "    learing_rate = 0.01\n",
    "    \n",
    "with tf.name_scope(\"LossFunction\"):\n",
    "    loss_function = tf.reduce_mean(tf.pow(y-pred, 2)) # 均方误差\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learing_rate).minimize(loss_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1  loss= 80.4272956766  b= 15.3306  w= [[-0.20103727]\n",
      " [ 0.66730869]\n",
      " [-0.04833315]\n",
      " [-0.00618632]\n",
      " [ 0.01075275]\n",
      " [ 0.1643074 ]\n",
      " [ 0.77208495]\n",
      " [ 0.12973753]\n",
      " [-0.03631233]\n",
      " [ 2.51394629]\n",
      " [ 4.18369055]\n",
      " [-2.9566164 ]]\n",
      "epoch= 2  loss= 79.3057991878  b= 23.9899  w= [[ -5.71969271e-01]\n",
      " [  1.81897187e+00]\n",
      " [ -3.12189996e-01]\n",
      " [  5.79309301e-04]\n",
      " [  1.17756333e-02]\n",
      " [  2.99539894e-01]\n",
      " [  3.66876185e-01]\n",
      " [  2.35166281e-01]\n",
      " [ -3.30767334e-01]\n",
      " [ -2.18316317e+00]\n",
      " [  5.35619640e+00]\n",
      " [ -9.44185829e+00]]\n",
      "epoch= 3  loss= 60.3896739881  b= 28.0088  w= [[ -8.27060282e-01]\n",
      " [  2.64787936e+00]\n",
      " [ -5.11465430e-01]\n",
      " [  6.33948995e-03]\n",
      " [  1.12234913e-02]\n",
      " [  3.85941952e-01]\n",
      " [ -2.66184658e-02]\n",
      " [  2.83520281e-01]\n",
      " [ -4.98905987e-01]\n",
      " [ -5.53565931e+00]\n",
      " [  5.22362900e+00]\n",
      " [ -1.49833126e+01]]\n",
      "epoch= 4  loss= 51.8847905449  b= 29.8234  w= [[ -1.00907850e+00]\n",
      " [  3.23370743e+00]\n",
      " [ -6.61397636e-01]\n",
      " [  1.18175475e-02]\n",
      " [  1.03717316e-02]\n",
      " [  4.46295440e-01]\n",
      " [ -3.09345186e-01]\n",
      " [  2.97563523e-01]\n",
      " [ -5.79973698e-01]\n",
      " [ -7.81347942e+00]\n",
      " [  4.53036118e+00]\n",
      " [ -1.95148945e+01]]\n",
      "epoch= 5  loss= 46.9327891678  b= 31.8989  w= [[ -1.12110245e+00]\n",
      " [  3.74909306e+00]\n",
      " [ -7.50360608e-01]\n",
      " [  1.69655625e-02]\n",
      " [  1.06629841e-02]\n",
      " [  5.04016161e-01]\n",
      " [ -3.60193223e-01]\n",
      " [  3.01245630e-01]\n",
      " [ -5.92385232e-01]\n",
      " [ -8.43730450e+00]\n",
      " [  4.09100628e+00]\n",
      " [ -2.29136677e+01]]\n",
      "epoch= 6  loss= 44.6039368032  b= 32.9531  w= [[ -1.21256506e+00]\n",
      " [  4.15205908e+00]\n",
      " [ -8.13887775e-01]\n",
      " [  2.20590997e-02]\n",
      " [  1.07199950e-02]\n",
      " [  5.49656570e-01]\n",
      " [ -3.64049226e-01]\n",
      " [  2.89602190e-01]\n",
      " [ -5.71725428e-01]\n",
      " [ -8.66658115e+00]\n",
      " [  3.39619851e+00]\n",
      " [ -2.57347240e+01]]\n",
      "epoch= 7  loss= 43.5481624586  b= 33.5144  w= [[ -1.28282332e+00]\n",
      " [  4.48861980e+00]\n",
      " [ -8.62153113e-01]\n",
      " [  2.70712767e-02]\n",
      " [  1.07850106e-02]\n",
      " [  5.88842034e-01]\n",
      " [ -3.25968832e-01]\n",
      " [  2.68741131e-01]\n",
      " [ -5.33809066e-01]\n",
      " [ -8.69281864e+00]\n",
      " [  2.57504249e+00]\n",
      " [ -2.81770535e+01]]\n",
      "epoch= 8  loss= 41.8827227177  b= 35.0933  w= [[ -1.33081579e+00]\n",
      " [  4.79156256e+00]\n",
      " [ -8.76229703e-01]\n",
      " [  3.21647376e-02]\n",
      " [  1.19135734e-02]\n",
      " [  6.35171592e-01]\n",
      " [ -1.22150943e-01]\n",
      " [  2.47546926e-01]\n",
      " [ -4.66666341e-01]\n",
      " [ -7.81042433e+00]\n",
      " [  2.19147635e+00]\n",
      " [ -2.99104424e+01]]\n",
      "epoch= 9  loss= 41.1687622088  b= 34.3983  w= [[ -1.37962627e+00]\n",
      " [  5.04083252e+00]\n",
      " [ -9.21151400e-01]\n",
      " [  3.68367136e-02]\n",
      " [  1.14302952e-02]\n",
      " [  6.60179555e-01]\n",
      " [ -8.17210004e-02]\n",
      " [  2.13798225e-01]\n",
      " [ -4.24431711e-01]\n",
      " [ -8.15745449e+00]\n",
      " [  9.84312177e-01]\n",
      " [ -3.19542274e+01]]\n",
      "epoch= 10  loss= 40.6036047351  b= 34.754  w= [[ -1.41400528e+00]\n",
      " [  5.25251436e+00]\n",
      " [ -9.34412360e-01]\n",
      " [  4.15087119e-02]\n",
      " [  1.19577255e-02]\n",
      " [  6.92360282e-01]\n",
      " [  1.14616886e-01]\n",
      " [  1.81331933e-01]\n",
      " [ -3.53075176e-01]\n",
      " [ -7.58218813e+00]\n",
      " [  2.36669764e-01]\n",
      " [ -3.33098259e+01]]\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(10):\n",
    "    loss_sum = 0.0\n",
    "    for xs, ys in zip(x_data, y_data):\n",
    "        xs = xs.reshape(1,12)\n",
    "        ys = ys.reshape(1,1)\n",
    "        \n",
    "        _, loss = sess.run([optimizer, loss_function], feed_dict={\n",
    "            x:xs, y:ys\n",
    "        })\n",
    "        \n",
    "        loss_sum = loss_sum + loss\n",
    "        \n",
    "    # 打乱样本集\n",
    "    x_data, y_data = shuffle(x_data, y_data)\n",
    "\n",
    "    b0temp = b.eval(session = sess)\n",
    "    w0temp = w.eval(session = sess)\n",
    "    loss_average = loss_sum/len(y_data)\n",
    "        \n",
    "    print(\"epoch=\", epoch+1, \" loss=\",loss_average, \" b=\", b0temp, \" w=\", w0temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
