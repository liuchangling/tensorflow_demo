Kaggle 机器学习竞赛



# 迁移学习
## what?
利用已训练好的模型作为新模型的初始化学习方式

比如利用vgg 得到的千分类结果，我们叫做预训练权重。
然后我们在后面添加学习权重，将其变为二分类。

## why
- 所需的样本数量少
- 达到收敛所需耗时更短


## when
- 当新数据集比较小且和原数据集相似
- 当算力有限时


## how
1. 当新数据集比较小且和原数据集相似 
只训练softmax层，即冻结前面所有层，视为特征提取器，只处理softmax。
2. 当有一定算力时，可以训练部分参数
即冻结前面大部分浅层，只训练后几个深层参数。
3. 有足够算力和样本时
训练全部层。迁移目的只是做一个初始化操作


对于计算机视觉而言，大部分时候都用迁移学习。除非你有非常非常大的样本集和足够的算力。


# Dogs vs Cats
利用给定数据集，实现猫/狗识别。
训练集 猫狗各 12500张。
测试集 猫狗一共12500张。
下载地址  https://www.kaggle.com/c/dogs-vs-cats/data


// TODO code....

## 微调 finetuining
- 对于不需要训练的层设置 trainable = False
- 修改全连接层的神经元个数